# app.py
# ARAM í”½ì°½ ê°œì¸í™” ì¶”ì²œ (ë‚´ 2025 ì „ì  + CompMLP) + ìŠ¤í¬ë¦°ìƒ· ì¸ì‹(Î²)

import os, io, re, json, requests, numpy as np, pandas as pd, streamlit as st, torch
import torch.nn as nn
from sklearn.preprocessing import OrdinalEncoder
from PIL import Image

# gdown (ìˆìœ¼ë©´ ì‚¬ìš©, ì—†ìœ¼ë©´ requests í´ë°±)
try:
    import gdown
    HAS_GDOWN = True
except Exception:
    HAS_GDOWN = False

# PyTorchê°€ sklearn ê°ì²´ë¥¼ ì•ˆì „ ë¡œë“œí•  ìˆ˜ ìˆê²Œ ë“±ë¡
from torch.serialization import add_safe_globals
add_safe_globals([OrdinalEncoder])

st.set_page_config(page_title="ARAM í”½ì°½ ê°œì¸í™” ì¶”ì²œ", page_icon="ğŸ¯", layout="wide")
st.title("ğŸ¯ ARAM í”½ì°½ ê°œì¸í™” ì¶”ì²œ (ë‚´ 2025 ì „ì  + CompMLP)")

# ------------------------------------------------------------------
# ê¸°ë³¸ ì„¤ì •
# ------------------------------------------------------------------
LANG = "ko_KR"
LOCAL_MODEL_PATH = "model/pregame_mlp_comp.pt"  # ë ˆí¬ì— ì—†ìœ¼ë©´ MODEL_URLë¡œ ë‹¤ìš´ë¡œë“œ
os.makedirs("model", exist_ok=True)

# ------------------------------------------------------------------
# Data Dragon ì •ì  ì •ë³´ (ì±”í”¼ì–¸/ë£¬)
# ------------------------------------------------------------------
@st.cache_data(show_spinner=False)
def ddragon_latest_version():
    try:
        return requests.get("https://ddragon.leagueoflegends.com/api/versions.json", timeout=10).json()[0]
    except Exception:
        return "14.14.1"

@st.cache_data(show_spinner=True)
def load_champion_static(lang=LANG):
    ver = ddragon_latest_version()
    url = f"https://ddragon.leagueoflegends.com/cdn/{ver}/data/{lang}/champion.json"
    data = requests.get(url, timeout=20).json()["data"]
    rows = []
    for _, v in data.items():
        rows.append({
            "championId": int(v["key"]),
            "name": v["name"],
            "id": v["id"],
            "tags": v.get("tags", []),
            "icon": f"https://ddragon.leagueoflegends.com/cdn/{ver}/img/champion/{v['id']}.png",
        })
    df = pd.DataFrame(rows).sort_values("championId")
    id2name = {r.championId: r.name for r in df.itertuples()}
    id2icon = {r.championId: r.icon for r in df.itertuples()}
    id2tags = {r.championId: r.tags for r in df.itertuples()}
    name2id = {r.name: r.championId for r in df.itertuples()}
    return df, id2name, id2icon, id2tags, name2id

@st.cache_data(show_spinner=True)
def load_runes_static(lang=LANG):
    """
    runesReforged.jsonì„ ë¶ˆëŸ¬ IDâ†’ì´ë¦„ ë§¤í•‘ì„ ë§Œë“ ë‹¤.
    - style_id2name: 8000/8100/... â†’ "ì •ë°€"/"ì§€ë°°"/...
    - keystone_id2name: 8128/8010/... â†’ "ê°ì „"/"ì •ë³µì"/...
    """
    ver = ddragon_latest_version()
    url = f"https://ddragon.leagueoflegends.com/cdn/{ver}/data/{lang}/runesReforged.json"
    data = requests.get(url, timeout=20).json()

    style_id2name = {}
    keystone_id2name = {}
    for style in data:
        style_id2name[style["id"]] = style["name"]
        if style.get("slots"):
            # ìŠ¬ë¡¯0 = í‚¤ìŠ¤í†¤
            for r in style["slots"][0].get("runes", []):
                keystone_id2name[r["id"]] = r["name"]
    return style_id2name, keystone_id2name

champ_df, id2name, id2icon, id2tags, name2id = load_champion_static()
style_id2name, keystone_id2name = load_runes_static()

# ------------------------------------------------------------------
# ì²´í¬í¬ì¸íŠ¸ ëª¨ì–‘ì„ ê·¸ëŒ€ë¡œ ë³µì›í•˜ëŠ” ëª¨ë¸ ë¡œë” (í¬ê¸° mismatch ë°©ì§€)
# ------------------------------------------------------------------
class CompMLP_Exact(nn.Module):
    """
    ì²´í¬í¬ì¸íŠ¸(state_dict)ì—ì„œ ì„ë² ë”©/ë ˆì´ì–´ ì°¨ì›ì„ ì½ì–´ 'ê·¸ëŒ€ë¡œ' ë³µì›.
    allies/enemies ìŠ¬ë¡¯ ê°œìˆ˜ë„ ì…ë ¥ì°¨ì›ì—ì„œ ì—­ì‚°.
    """
    def __init__(self, n_champ, d_champ,
                 n_sp, d_sp, n_pri, d_pri, n_sub, d_sub, n_key, d_key, n_pat, d_pat,
                 in_dim, h1, h2, use_dropout, allies, enemies):
        super().__init__()
        # Embeddings
        self.emb_champ = nn.Embedding(n_champ, d_champ)
        self.emb_sp  = nn.Embedding(n_sp,  d_sp)
        self.emb_pri = nn.Embedding(n_pri, d_pri)
        self.emb_sub = nn.Embedding(n_sub, d_sub)
        self.emb_key = nn.Embedding(n_key, d_key)
        self.emb_pat = nn.Embedding(n_pat, d_pat)

        self.n_allies = allies
        self.n_enemies = enemies

        # MLP
        if use_dropout:
            self.mlp = nn.Sequential(
                nn.Linear(in_dim, h1),  # 0
                nn.ReLU(),              # 1
                nn.Dropout(0.2),        # 2
                nn.Linear(h1, h2),      # 3
                nn.ReLU(),              # 4
                nn.Linear(h2, 1),       # 5
            )
        else:
            self.mlp = nn.Sequential(
                nn.Linear(in_dim, h1),  # 0
                nn.ReLU(),              # 1
                nn.Linear(h1, h2),      # 2
                nn.ReLU(),              # 3
                nn.Linear(h2, 1),       # 4
            )

    def forward(self, my_idx, ally_lists, enem_lists, misc_idx):
        # ----- ì„ë² ë”© ëª¨ìŒ -----
        me = self.emb_champ(my_idx)  # [B, d_champ]

        # allies/enemies ê°œìˆ˜ ì •í™•íˆ ë§ì¶”ê¸°(íŒ¨ë”©/íŠ¸ë ì¼€ì´íŠ¸)
        allies = [self.emb_champ(a) for a in ally_lists[: self.n_allies]]
        for _ in range(max(0, self.n_allies - len(allies))):
            allies.append(self.emb_champ(torch.zeros_like(my_idx)))  # index 0 íŒ¨ë”©

        enemies = [self.emb_champ(e) for e in enem_lists[: self.n_enemies]]
        for _ in range(max(0, self.n_enemies - len(enemies))):
            enemies.append(self.emb_champ(torch.zeros_like(my_idx)))  # index 0 íŒ¨ë”©

        # misc 5ì¢…(ìˆœì„œ ê³ ì •)
        sp  = self.emb_sp(misc_idx[:, 0])
        pri = self.emb_pri(misc_idx[:, 1])
        sub = self.emb_sub(misc_idx[:, 2])
        key = self.emb_key(misc_idx[:, 3])
        pat = self.emb_pat(misc_idx[:, 4])
        misc = torch.cat([sp, pri, sub, key, pat], dim=-1)  # [B, misc_sum]

        # ----- ì‹¤ì œ ì…ë ¥ ë²¡í„° -----
        x = torch.cat([me, *allies, *enemies, misc], dim=-1)  # [B, cur_dim]

        # ===== ì•ˆì „ ê°€ë“œ: in_featuresì™€ ì •í™•íˆ ë§ì¶”ê¸° =====
        try:
            first_linear = self.mlp[0]
            expect = int(first_linear.in_features)
        except Exception:
            expect = None
            for mod in self.mlp:
                if isinstance(mod, torch.nn.Linear):
                    expect = int(mod.in_features)
                    break

        if expect is not None:
            cur = int(x.size(-1))
            if cur != expect:
                if not hasattr(self, "_dim_warned"):
                    import streamlit as st
                    st.warning(
                        f"[ì…ë ¥ ì°¨ì› ìë™ ë³´ì •] cur_dim={cur}, expect={expect} "
                        f"(allies={self.n_allies}, enemies={self.n_enemies})"
                    )
                    self._dim_warned = True
                if cur < expect:
                    pad = torch.zeros(x.size(0), expect - cur, device=x.device, dtype=x.dtype)
                    x = torch.cat([x, pad], dim=-1)
                else:
                    x = x[..., :expect]

        return self.mlp(x).squeeze(-1)

def _infer_model_from_state(sd):
    # --- ì„ë² ë”© ëª¨ì–‘ ---
    n_champ, d_champ = sd["emb_champ.weight"].shape
    n_sp, d_sp   = sd["emb_sp.weight"].shape
    n_pri, d_pri = sd["emb_pri.weight"].shape
    n_sub, d_sub = sd["emb_sub.weight"].shape
    n_key, d_key = sd["emb_key.weight"].shape
    n_pat, d_pat = sd["emb_pat.weight"].shape

    # --- MLP í¬ê¸°/ë“œë¡­ì•„ì›ƒ ---
    in_dim = sd["mlp.0.weight"].shape[1]
    h1     = sd["mlp.0.weight"].shape[0]
    use_dropout = ("mlp.3.weight" in sd and "mlp.2.weight" not in sd)
    h2 = sd["mlp.3.weight"].shape[0] if use_dropout else sd["mlp.2.weight"].shape[0]

    misc_sum = d_sp + d_pri + d_sub + d_key + d_pat

    # allies/enemies ìë™ íƒìƒ‰ (ì •í™•íˆ in_dim ì¼ì¹˜)
    best = None
    for allies in range(0, 6):
        for enemies in range(0, 10):
            expect = d_champ * (1 + allies + enemies) + misc_sum
            if expect == in_dim:
                score = -abs(allies - 4) * 10 + enemies  # allies=4 ì„ í˜¸
                cand = (score, allies, enemies)
                if best is None or cand > best:
                    best = cand
    if best is None:
        total_slots = (in_dim - misc_sum) // d_champ
        allies = 4
        enemies = max(total_slots - 1 - allies, 0)
    else:
        allies = best[1]
        enemies = best[2]

    return dict(
        n_champ=n_champ, d_champ=d_champ,
        n_sp=n_sp, d_sp=d_sp, n_pri=n_pri, d_pri=d_pri,
        n_sub=n_sub, d_sub=d_sub, n_key=n_key, d_key=d_key,
        n_pat=n_pat, d_pat=d_pat,
        in_dim=in_dim, h1=h1, h2=h2, use_dropout=use_dropout,
        allies=allies, enemies=enemies
    )

def enc_misc_row(enc: OrdinalEncoder, row: dict):
    vals = [[
        row.get("spell_pair", "__UNK__"),
        row.get("primaryStyle", "__UNK__"),
        row.get("subStyle", "__UNK__"),
        row.get("keystone", "__UNK__"),
        row.get("patch", "__UNK__"),
    ]]
    arr = enc.transform(vals).astype(int)  # -1 í¬í•¨ ê°€ëŠ¥
    for j in range(arr.shape[1]):
        if arr[0, j] < 0:
            arr[0, j] = len(enc.categories_[j])  # UNK = ë§ˆì§€ë§‰ ì¸ë±ìŠ¤
    return torch.tensor(arr, dtype=torch.long)

# ---- Google Drive í—¬í¼ ----
def _extract_drive_file_id(url: str) -> str | None:
    if not url:
        return None
    for pat in [r"/d/([A-Za-z0-9_-]{10,})", r"[?&]id=([A-Za-z0-9_-]{10,})"]:
        m = re.search(pat, url)
        if m:
            return m.group(1)
    return None

def ensure_model_file(local_path: str, url: str):
    if os.path.exists(local_path):
        return local_path
    if not url:
        return None

    fid = _extract_drive_file_id(url)

    try:
        if fid and HAS_GDOWN:
            gdown.download(f"https://drive.google.com/uc?id={fid}", local_path, quiet=False)
        else:
            dl_url = f"https://drive.google.com/uc?id={fid}&confirm=t" if fid else url
            with requests.get(dl_url, stream=True, timeout=120) as r:
                r.raise_for_status()
                with open(local_path, "wb") as f:
                    for chunk in r.iter_content(1024 * 1024):
                        if chunk:
                            f.write(chunk)
    except Exception as e:
        st.error(f"ëª¨ë¸ ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨: {e}")
        return None

    # íŒŒì¼ ê²€ì¦: HTML ë°›ì•˜ëŠ”ì§€ ì²´í¬
    try:
        with open(local_path, "rb") as f:
            head = f.read(32)
        if head.strip().startswith(b"<"):
            raise ValueError("ë‹¤ìš´ë¡œë“œëœ ë‚´ìš©ì´ HTMLì…ë‹ˆë‹¤. ë“œë¼ì´ë¸Œ ê³µìœ  ì„¤ì • ë˜ëŠ” ë§í¬ë¥¼ í™•ì¸í•˜ì„¸ìš”.")
    except Exception as e:
        st.error(f"ëª¨ë¸ íŒŒì¼ ê²€ì¦ ì‹¤íŒ¨: {e}")
        try:
            os.remove(local_path)
        except Exception:
            pass
        return None

    return local_path

@st.cache_resource(show_spinner=True)
def load_model(local_path: str):
    if not os.path.exists(local_path):
        return None
    # sklearn ê°ì²´ í¬í•¨ â†’ weights_only=False
    obj = torch.load(local_path, map_location="cpu", weights_only=False)

    state_dict   = obj["state_dict"]
    champ_id2idx = obj["champ_id2idx"]
    enc_misc     = obj["enc_misc"]

    spec = _infer_model_from_state(state_dict)
    model = CompMLP_Exact(
        spec["n_champ"], spec["d_champ"],
        spec["n_sp"], spec["d_sp"], spec["n_pri"], spec["d_pri"],
        spec["n_sub"], spec["d_sub"], spec["n_key"], spec["d_key"],
        spec["n_pat"], spec["d_pat"], spec["in_dim"], spec["h1"],
        spec["h2"], spec["use_dropout"], spec["allies"], spec["enemies"]
    )
    model.load_state_dict(state_dict)
    model.eval()
    return {"model": model, "champ_id2idx": champ_id2idx, "enc_misc": enc_misc,
            "allies": spec["allies"], "enemies": spec["enemies"]}

@st.cache_resource(show_spinner=True)
def get_bundle():
    # 0) ë¡œì»¬ íŒŒì¼ì´ HTML/ê¹¨ì§„ íŒŒì¼ì¸ì§€ ì‚¬ì „ ê²€ì¦ â†’ ìˆìœ¼ë©´ ì‚­ì œ
    if os.path.exists(LOCAL_MODEL_PATH):
        try:
            with open(LOCAL_MODEL_PATH, "rb") as f:
                head = f.read(32)
            if head.strip().startswith(b"<"):
                os.remove(LOCAL_MODEL_PATH)
        except Exception:
            pass

    # 1) ë¡œì»¬ ìš°ì„  ë¡œë“œ ì‹œë„
    if os.path.exists(LOCAL_MODEL_PATH):
        try:
            b = load_model(LOCAL_MODEL_PATH)
            if b:
                return b
        except Exception as e:
            try:
                os.remove(LOCAL_MODEL_PATH)
            except Exception:
                pass
            st.warning(f"ë¡œì»¬ ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨, URL ì¬ì‹œë„: {e}")

    # 2) Secrets/ENVì—ì„œ MODEL_URL ì½ì–´ ë‹¤ìš´ë¡œë“œ
    url = os.environ.get("MODEL_URL", "")
    if not url and "MODEL_URL" in st.secrets:
        url = st.secrets["MODEL_URL"].strip()

    if url:
        dl_path = LOCAL_MODEL_PATH
        path = ensure_model_file(dl_path, url)
        if path:
            try:
                b = load_model(path)
                if b:
                    return b
            except Exception as e:
                st.error(f"ë‹¤ìš´ë¡œë“œ ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {e}")

    st.error("ëª¨ë¸ ì¤€ë¹„ ì‹¤íŒ¨ (ë¡œì»¬ íŒŒì¼ ì—†ìŒ & MODEL_URL ë¯¸ì„¤ì •)")
    return None

bundle = get_bundle()
if bundle: st.sidebar.success("ëª¨ë¸ ì¤€ë¹„ ì™„ë£Œ âœ…")
else:      st.sidebar.error("ëª¨ë¸ ë¯¸ë¡œë”© âŒ")

def predict_prob_comp(bundle, my_cid, ally_ids, enemy_ids, misc_row):
    """ì²´í¬í¬ì¸íŠ¸ê°€ ê¸°ëŒ€í•˜ëŠ” allies/enemies ê°œìˆ˜ì— ë§ì¶° íŒ¨ë”©/íŠ¸ë ì¼€ì´íŠ¸"""
    if bundle is None:
        return 0.5

    model = bundle["model"]
    c2i   = bundle["champ_id2idx"]
    enc   = bundle["enc_misc"]
    na    = bundle.get("allies", 4)
    ne    = bundle.get("enemies", 5)

    device = torch.device("cpu")
    unk_idx = len(c2i)  # ë¯¸ë“±ë¡ id â†’ ë§ˆì§€ë§‰ ì¸ë±ìŠ¤ ì‚¬ìš©

    def pad(ids, need):
        ids = [int(x) for x in ids][:need]
        while len(ids) < need:
            ids.append(0)
        return ids

    # 1ì°¨ì› [1] í…ì„œ
    my = torch.tensor([c2i.get(int(my_cid), unk_idx)], dtype=torch.long).to(device)  # [1]
    ally = torch.tensor([c2i.get(i, unk_idx) for i in pad(ally_ids, na)], dtype=torch.long)  # [na]
    ally = ally.unsqueeze(0).to(device)  # [1, na]
    enem = torch.tensor([c2i.get(i, unk_idx) for i in pad(enemy_ids, ne)], dtype=torch.long) # [ne]
    enem = enem.unsqueeze(0).to(device)  # [1, ne]
    misc = enc_misc_row(enc, misc_row).to(device)                                           # [1, 5]

    with torch.no_grad():
        out = model(
            my,                               # [1]
            [ally[:, i] for i in range(ally.shape[1])],   # ê° ì›ì†ŒëŠ” [1]
            [enem[:, i] for i in range(enem.shape[1])],   # ê° ì›ì†ŒëŠ” [1]
            misc                              # [1, 5]
        )
        prob = torch.sigmoid(out).cpu().item()

    return float(prob)

# ------------------------------------------------------------------
# ë‚´ ì „ì  CSV ë¡œë“œ
# ------------------------------------------------------------------
st.sidebar.header("1) ë‚´ ì „ì  CSV")
csv_mode = st.sidebar.radio("ë¶ˆëŸ¬ì˜¤ê¸° ë°©ì‹", ["GitHub RAW URL", "íŒŒì¼ ì—…ë¡œë“œ"], horizontal=True)
df_pre = None
if csv_mode == "GitHub RAW URL":
    url = st.sidebar.text_input("RAW CSV URL", value="")
    if url:
        try:
            df_pre = pd.read_csv(url)
            st.sidebar.success(f"CSV ë¡œë“œ: {len(df_pre)}í–‰")
        except Exception as e:
            st.sidebar.error(f"ë¡œë“œ ì‹¤íŒ¨: {e}")
else:
    up = st.sidebar.file_uploader("Drag & drop CSV", type=["csv"])
    if up:
        try:
            df_pre = pd.read_csv(up)
            st.sidebar.success(f"CSV ë¡œë“œ: {len[df_pre]}í–‰")
        except Exception as e:
            st.sidebar.error(f"ë¡œë“œ ì‹¤íŒ¨: {e}")

# ------------------------------------------------------------------
# ê°œì¸ ì„±í–¥/ìµœë¹ˆ ë£¬/ìŠ¤í 
# ------------------------------------------------------------------
def build_personal_stats(df: pd.DataFrame):
    if df is None or len(df)==0:
        return pd.DataFrame(columns=["championId","games","wins","wr","personal_score"])
    g = df.groupby("championId").agg(games=("win","size"), wins=("win","sum")).reset_index()
    g["wr"] = g["wins"]/g["games"]
    g["personal_score"] = g["wr"] + 0.1*np.log1p(g["games"])  # ê°„ë‹¨ ë³´ì •
    return g

def per_champ_misc_modes(df: pd.DataFrame):
    if df is None or len(df)==0:
        return {}
    cols = ["championId","spell_pair","primaryStyle","subStyle","keystone","patch"]
    for c in cols:
        if c not in df.columns: df[c] = "__UNK__"
    modes = {}
    for cid, sub in df.groupby("championId"):
        mode = {}
        for c in ["spell_pair","primaryStyle","subStyle","keystone","patch"]:
            s = sub[c].mode(dropna=True)
            mode[c] = s.iloc[0] if not s.empty else "__UNK__"
        modes[int(cid)] = mode
    return modes

# ê°„ë‹¨ ìŠ¤í /ë£¬ ì¶”ì²œ íœ´ë¦¬ìŠ¤í‹±
ARAM_SPELLS = {
    "Mark":"ëˆˆë©ì´", "Exhaust":"íƒˆì§„", "Ignite":"ì í™”", "Ghost":"ìœ ì²´í™”",
    "Heal":"íšŒë³µ", "Barrier":"ë°©ì–´ë§‰", "Cleanse":"ì •í™”", "Clarity":"ì´ëª…"
}
def suggest_spells_for_champ(cid: int, id2tags: dict, ally_ids: list[int], enemy_ids: list[int]):
    tags = set(id2tags.get(cid, []))
    second = "ìœ ì²´í™”"
    if "Assassin" in tags or "Mage" in tags: second = "ì í™”"
    if any("Assassin" in id2tags.get(e, []) for e in enemy_ids): second = "íƒˆì§„"
    if "Marksman" in tags and any("Assassin" in id2tags.get(e, []) for e in enemy_ids): second = "íƒˆì§„"
    return ["ëˆˆë©ì´", second]

def suggest_runes_from_modes(cid: int, misc_modes: dict):
    m = misc_modes.get(cid, {})
    ps = m.get("primaryStyle", "")
    ss = m.get("subStyle", "")
    ks = m.get("keystone", "")

    def to_int(x):
        try: return int(x)
        except Exception: return None

    psn = style_id2name.get(to_int(ps), str(ps))          # ìŠ¤íƒ€ì¼ ì´ë¦„
    ssn = style_id2name.get(to_int(ss), str(ss))          # ë³´ì¡° ìŠ¤íƒ€ì¼ ì´ë¦„
    ksn = keystone_id2name.get(to_int(ks), str(ks))       # í‚¤ìŠ¤í†¤ ì´ë¦„
    return {"primaryStyle": psn, "subStyle": ssn, "keystone": ksn}

def personal_spell_from_df(df: pd.DataFrame, cid: int, min_games: int = 3):
    """
    ë‚´ CSVì—ì„œ í•´ë‹¹ ì±”í”¼ì–¸ì˜ ìµœë¹ˆ ìŠ¤í  ì¡°í•©ì„ ê°€ì ¸ì™€ ì¶”ì²œ.
    - í‘œë³¸ ìˆ˜ê°€ min_games ë¯¸ë§Œì´ë©´ None â†’ íœ´ë¦¬ìŠ¤í‹± í´ë°±
    - CSV 'spell_pair'ê°€ "ëˆˆë©ì´+ì í™”" í˜•ì‹ì´ë¼ê³  ê°€ì •
    """
    if df is None or len(df) == 0 or "spell_pair" not in df.columns:
        return None
    sub = df[(df["championId"] == cid) & (df["spell_pair"].notna())]
    if sub.empty:
        return None
    cnt = sub.groupby("spell_pair").size().sort_values(ascending=False)
    top_pair = cnt.index[0]
    if cnt.iloc[0] < min_games:
        return None
    parts = [p.strip() for p in str(top_pair).split("+") if p.strip()]
    if len(parts) == 2:
        return parts
    return None

def comp_bonus_score(my_cid, ally_ids, id2tags):
    tags_me = set(id2tags.get(my_cid, []))
    allies = [set(id2tags.get(i, [])) for i in ally_ids]
    score = 0.0
    if "Tank" in tags_me and not any("Tank" in t for t in allies): score += 0.05
    if "Support" in tags_me and not any("Support" in t for t in allies): score += 0.05
    ap_like = {"Mage","Support"}; ad_like = {"Marksman","Fighter","Assassin"}
    ally_ap = sum(any(tt in ap_like for tt in t) for t in allies)
    ally_ad = sum(any(tt in ad_like for tt in t) for t in allies)
    if "Mage" in tags_me and ally_ap<=1: score += 0.03
    if "Marksman" in tags_me and ally_ad<=1: score += 0.03
    return min(score, 0.15)

# ------------------------------------------------------------------
# [ìˆ˜ë™ ì…ë ¥] í”½ì°½ UI
# ------------------------------------------------------------------
st.markdown("## 3) í”½ì°½ ì…ë ¥")
c1, c2 = st.columns(2)
with c1:
    ally_names = st.multiselect("ì•„êµ° ì±”í”¼ì–¸", champ_df["name"].tolist(), max_selections=4)
with c2:
    enemy_names = st.multiselect("ìƒëŒ€ ì±”í”¼ì–¸ (ì„ íƒ)", champ_df["name"].tolist(), max_selections=5)

cand_names = st.multiselect("í›„ë³´ ì±”í”¼ì–¸ (ì„ íƒ)", champ_df["name"].tolist(), help="ì—¬ê¸°ì— ë„£ì€ í›„ë³´ë“¤ë§Œ ì ìˆ˜í™”í•©ë‹ˆë‹¤.")
alpha = st.slider("Î± ëª¨ë¸ ê°€ì¤‘ì¹˜", 0.0, 1.0, 0.60, 0.01)
beta  = st.slider("Î² ê°œì¸ ì„±í–¥ ê°€ì¤‘ì¹˜", 0.0, 1.0, 0.35, 0.01)
gamma = st.slider("Î³ ì¡°í•© ë³´ë„ˆìŠ¤ ê°€ì¤‘ì¹˜", 0.0, 0.5, 0.05, 0.01)
min_games = st.number_input("ê°œì¸ ì„±í–¥ ìµœì†Œ í‘œë³¸", 0, 50, 5, step=1)

st.session_state["alpha"] = alpha
st.session_state["beta"]  = beta
st.session_state["gamma"] = gamma
st.session_state["min_games"] = min_games

if st.button("ğŸš€ ì¶”ì²œ ì‹¤í–‰"):
    if len(ally_names) != 4 or len(cand_names)==0:
        st.warning("ì•„êµ° 4ëª…ê³¼ í›„ë³´ë¥¼ ì„ íƒí•´ì£¼ì„¸ìš”.")
    else:
        ally_ids = [name2id[n] for n in ally_names]
        enemy_ids = [name2id[n] for n in enemy_names] if enemy_names else []

        per = build_personal_stats(df_pre) if df_pre is not None else pd.DataFrame(columns=["championId","games","wins","wr","personal_score"])
        per_map = per.set_index("championId").to_dict(orient="index") if len(per)>0 else {}
        misc_modes = per_champ_misc_modes(df_pre) if df_pre is not None else {}

        rows = []
        for cname in cand_names:
            cid = name2id[cname]
            meta = per_map.get(cid, {"games":0,"wins":0,"wr":np.nan,"personal_score":-0.5})
            ps   = meta["personal_score"] - (0.3 if meta["games"]<min_games else 0.0)

            mode = misc_modes.get(cid, {})
            misc_row = {
                "spell_pair": str(mode.get("spell_pair","__UNK__")),
                "primaryStyle": str(mode.get("primaryStyle","__UNK__")),
                "subStyle": str(mode.get("subStyle","__UNK__")),
                "keystone": str(mode.get("keystone","__UNK__")),
                "patch": str(mode.get("patch","__UNK__")),
            }
            prob  = predict_prob_comp(bundle, cid, ally_ids, enemy_ids, misc_row)
            bonus = comp_bonus_score(cid, ally_ids, id2tags)
            score = alpha*prob + beta*ps + gamma*bonus

            rune = suggest_runes_from_modes(cid, misc_modes)
            spells = personal_spell_from_df(df_pre, cid, min_games=min_games) \
                     or suggest_spells_for_champ(cid, id2tags, ally_ids, enemy_ids)

            rows.append({
                "icon": id2icon.get(cid,""),
                "ì±”í”¼ì–¸": cname,
                "ì˜ˆì¸¡ìŠ¹ë¥ Î±(%)": round(prob*100,2),
                "ì¡°í•©ë³´ë„ˆìŠ¤Î³(%)": round(bonus*100,2),
                "ê°œì¸_ê²Œì„ìˆ˜": meta.get("games",0),
                "ê°œì¸_ìŠ¹ë¥ (%)": round(meta.get("wr",0)*100,2) if pd.notna(meta.get("wr")) else None,
                "ì¶”ì²œ_ìŠ¤í ": " + ".join(spells),
                "ì¶”ì²œ_ë£¬": f"ì£¼{rune['primaryStyle']} Â· ë¶€{rune['subStyle']} Â· í•µì‹¬{rune['keystone']}",
                "ì ìˆ˜": score
            })

        out = pd.DataFrame(rows).sort_values("ì ìˆ˜", ascending=False).reset_index(drop=True)

        st.subheader("ì¶”ì²œ ê²°ê³¼")
        top3 = out.head(3)
        cols = st.columns(len(top3))
        for col, (_, r) in zip(cols, top3.iterrows()):
            with col:
                if r["icon"]: st.image(r["icon"], width=64)
                st.markdown(f"**{r['ì±”í”¼ì–¸']}**")
                st.write(f"ì˜ˆì¸¡ {r['ì˜ˆì¸¡ìŠ¹ë¥ Î±(%)']}% | ë³´ë„ˆìŠ¤ {r['ì¡°í•©ë³´ë„ˆìŠ¤Î³(%)']}%")
                st.write(f"ìŠ¤í : {r['ì¶”ì²œ_ìŠ¤í ']}")
                st.write(r["ì¶”ì²œ_ë£¬"])

        # === ì „ì²´ í‘œ (ì•„ì´ì½˜ ì‹¤ì œ ì´ë¯¸ì§€ ë Œë”) ===
        st.subheader("ì „ì²´ í‘œ")
        table = out.drop(columns=["ì ìˆ˜"]).copy()
        st.dataframe(
            table,
            column_config={
                "icon": st.column_config.ImageColumn(" ", help="ì±”í”¼ì–¸ ì•„ì´ì½˜", width="small")
            },
            use_container_width=True,
        )

# ------------------------------------------------------------------
# ğŸ–¼ï¸ ìŠ¤í¬ë¦°ìƒ· ì—…ë¡œë“œ â†’ ìë™ ì¸ì‹ (Vertex AI)
# ------------------------------------------------------------------
st.markdown("---")
st.header("ğŸ–¼ï¸ í”½ì°½ ìŠ¤í¬ë¦°ìƒ·ìœ¼ë¡œ ìë™ ì¶”ì²œ (Î²)")

def init_vertex():
    try:
        import vertexai
        from vertexai.generative_models import GenerativeModel
    except Exception as e:
        st.error(f"Vertex AI ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ ì—†ìŠµë‹ˆë‹¤: {e}")
        return None

    proj = st.secrets.get("GCP_PROJECT", "")
    loc  = st.secrets.get("GCP_LOCATION", "us-central1")
    sa_raw = st.secrets.get("GCP_SA_JSON", "")
    if not (proj and sa_raw):
        st.info("Secretsì— GCP_PROJECT, GCP_LOCATION, GCP_SA_JSONì„ ì„¤ì •í•˜ì„¸ìš”.")
        return None

    try:
        sa_obj = json.loads(sa_raw)
    except Exception as e:
        st.error(f"GCP_SA_JSON íŒŒì‹± ì‹¤íŒ¨: {e}")
        return None

    key_path = "/tmp/gcp_key.json"
    with open(key_path, "w", encoding="utf-8") as f:
        json.dump(sa_obj, f)
    os.environ["GOOGLE_APPLICATION_CREDENTIALS"] = key_path

    import vertexai
    vertexai.init(project=proj, location=loc)
    from vertexai.generative_models import GenerativeModel

    prefer = st.secrets.get("GEMINI_MODEL", "gemini-1.5-flash-002")
    candidates = [prefer, "gemini-2.5-flash-lite-001", "gemini-2.0-flash-001",
                  "gemini-1.5-flash-002", "gemini-1.0-pro-vision-001"]

    last_err = None
    for m in candidates:
        try:
            model = GenerativeModel(m)
            test = model.generate_content(["ping"], generation_config={"max_output_tokens": 1})
            if not getattr(test, "candidates", None):
                raise RuntimeError("ëª¨ë¸ ì‘ë‹µì´ ë¹„ì–´ìˆìŒ")
            st.caption(f"Using Gemini model: **{m}**")
            return model
        except Exception as e:
            last_err = e
            continue

    st.error(f"Gemini ëª¨ë¸ ì ‘ê·¼ ì‹¤íŒ¨: {last_err}")
    st.info("â€¢ í”„ë¡œì íŠ¸/ë¦¬ì „(us-central1)/ì—­í• (roles:aiplatform.user)/ê²°ì œ í™œì„±í™” ì—¬ë¶€ë¥¼ í™•ì¸í•˜ì„¸ìš”.")
    return None

def _names_to_ids(names):
    return [int(name2id[n]) for n in names if n in name2id]

up_img = st.file_uploader("í”½ì°½ ìŠ¤í¬ë¦°ìƒ· ì—…ë¡œë“œ (PNG/JPG)", type=["png","jpg","jpeg"])
if up_img and st.button("ğŸ” ìŠ¤ìƒ· ì¸ì‹ & ì¶”ì²œ"):
    img = Image.open(up_img).convert("RGB")
    st.image(img, caption="ì…ë ¥ ì´ë¯¸ì§€", use_container_width=True)

    model = init_vertex()
    if model is None:
        st.stop()

    from vertexai.generative_models import Part
    sys_prompt = (
        "You extract ARAM pick-phase info from screenshots. "
        "Return STRICT JSON with keys: ally_champions (string[]), candidate_champions (string[]). "
        "Names must be Korean exactly as shown in the League client. If not visible, return empty arrays. JSON only."
    )
    user_prompt = (
        "ì´ ì´ë¯¸ì§€ëŠ” ë¬´ì‘ìœ„ ì´ë ¥ì „(ARAM) í”½ì°½ì…ë‹ˆë‹¤. ì™¼ìª½ì˜ ì•„êµ° 4ëª…ê³¼ ìƒë‹¨ í›„ë³´ ì±”í”¼ì–¸ì„ ì½ì–´ "
        "ë‹¤ìŒ JSON í˜•ì‹ìœ¼ë¡œë§Œ ì¶œë ¥í•˜ì„¸ìš”.\n"
        "{\n"
        '  "ally_champions": ["ì´ˆê°€ìŠ¤","íƒ€ë¦­","ë²¨ë² ìŠ¤","ìš”ë„¤"],\n'
        '  "candidate_champions": ["ë‹¤ì´ì• ë‚˜","ëŸ­ìŠ¤","ì œë“œ"]\n'
        "}\n"
    )
    buf = io.BytesIO(); img.save(buf, format="PNG")

    resp = model.generate_content(
        [sys_prompt, Part.from_data(mime_type="image/png", data=buf.getvalue()), user_prompt],
        generation_config={"temperature": 0.1, "max_output_tokens": 512},
    )

    # ---- ì‘ë‹µ ë¬¸ìì—´ ì•ˆì „ ì¶”ì¶œ ----
    raw = ""
    if hasattr(resp, "text") and resp.text:
        raw = resp.text
    elif getattr(resp, "candidates", None):
        parts = []
        for c in resp.candidates:
            try:
                for p in getattr(c, "content", {}).parts or []:
                    if getattr(p, "text", None):
                        parts.append(p.text)
            except Exception:
                pass
        raw = "\n".join([p for p in parts if p])
    raw = (raw or "").strip()

    if not raw:
        st.error("ëª¨ë¸ ì‘ë‹µì´ ë¹„ì—ˆìŠµë‹ˆë‹¤. (ì¸ì¦/ê¶Œí•œ/ë¦¬ì „/ëª¨ë¸ëª…ì„ ë‹¤ì‹œ í™•ì¸)")
        st.stop()

    # ---- JSONë§Œ ì¶”ì¶œ ----
    m = re.search(r"\{[\s\S]*\}", raw)
    if not m:
        st.error("ì‘ë‹µì—ì„œ JSON ë¸”ë¡ì„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. í”„ë¡¬í”„íŠ¸ë¥¼ ë‹¤ì‹œ ë³´ë‚´ ë³´ì„¸ìš”.")
        st.code(raw, language="markdown")
        st.stop()

    json_str = m.group(0)
    try:
        data = json.loads(json_str)
    except Exception as e:
        st.error(f"JSON íŒŒì‹± ì‹¤íŒ¨: {e}")
        st.code(json_str, language="json")
        st.stop()

    st.subheader("ì¸ì‹ ê²°ê³¼")
    st.code(json.dumps(data, ensure_ascii=False, indent=2), language="json")

    ally_ids = _names_to_ids(data.get("ally_champions", []))
    cand_ids = _names_to_ids(data.get("candidate_champions", []))

    if len(ally_ids) != 4 or not cand_ids:
        st.info("ì•„êµ° 4ëª… ë˜ëŠ” í›„ë³´ê°€ ì¶©ë¶„íˆ ì¸ì‹ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ì´ë¯¸ì§€ í•´ìƒë„/ë°ê¸°ë¥¼ ë†’ì—¬ ë‹¤ì‹œ ì‹œë„í•´ ì£¼ì„¸ìš”.")
        st.stop()

    per = build_personal_stats(df_pre) if df_pre is not None else pd.DataFrame(columns=["championId","games","wins","wr","personal_score"])
    per_map = per.set_index("championId").to_dict(orient="index") if len(per)>0 else {}
    misc_modes = per_champ_misc_modes(df_pre) if df_pre is not None else {}

    alpha = st.session_state.get("alpha", 0.60)
    beta  = st.session_state.get("beta", 0.35)
    gamma = st.session_state.get("gamma", 0.05)
    min_games_used = st.session_state.get("min_games", 5)

    rows = []
    for cid in cand_ids:
        cname = id2name.get(cid, str(cid])
        meta = per_map.get(cid, {"games":0,"wins":0,"wr":np.nan,"personal_score":-0.5})
        ps   = meta["personal_score"] - (0.3 if meta["games"]<5 else 0.0)

        mode = misc_modes.get(cid, {})
        misc_row = {
            "spell_pair": str(mode.get("spell_pair","__UNK__")),
            "primaryStyle": str(mode.get("primaryStyle","__UNK__")),
            "subStyle": str(mode.get("subStyle","__UNK__")),
            "keystone": str(mode.get("keystone","__UNK__")),
            "patch": str(mode.get("patch","__UNK__")),
        }
        prob  = predict_prob_comp(bundle, cid, ally_ids, [], misc_row)
        bonus = comp_bonus_score(cid, ally_ids, id2tags)
        score = alpha*prob + beta*ps + gamma*bonus

        rune = suggest_runes_from_modes(cid, misc_modes)
        spells = personal_spell_from_df(df_pre, cid, min_games=min_games_used) \
                 or suggest_spells_for_champ(cid, id2tags, ally_ids, [])

        rows.append({
            "icon": id2icon.get(cid,""),
            "ì±”í”¼ì–¸": cname,
            "ì˜ˆì¸¡ìŠ¹ë¥ Î±(%)": round(prob*100,2),
            "ê°œì¸_ê²Œì„ìˆ˜": meta.get("games",0),
            "ê°œì¸_ìŠ¹ë¥ (%)": round(meta.get("wr",0)*100,2) if pd.notna(meta.get("wr")) else None,
            "ì¶”ì²œ_ìŠ¤í ": " + ".join(spells),
            "ì¶”ì²œ_ë£¬": f"ì£¼{rune['primaryStyle']} Â· ë¶€{rune['SubStyle']} Â· í•µì‹¬{rune['keystone']}",
            "ì ìˆ˜": score
        })

    out = pd.DataFrame(rows).sort_values("ì ìˆ˜", ascending=False).reset_index(drop=True)

    st.subheader("í›„ë³´ ì±”í”¼ì–¸ ì¶”ì²œ ìˆœìœ„")
    top3 = out.head(3)
    cols = st.columns(len(top3))
    for col, (_, r) in zip(cols, top3.iterrows()):
        with col:
            if r["icon"]: st.image(r["icon"], width=64)
            st.markdown(f"**{r['ì±”í”¼ì–¸']}**")
            st.write(f"ì˜ˆì¸¡ {r['ì˜ˆì¸¡ìŠ¹ë¥ Î±(%)']}%")
            st.write(f"ìŠ¤í : {r['ì¶”ì²œ_ìŠ¤í ']}")
            st.write(r["ì¶”ì²œ_ë£¬"])

    st.markdown("### ì „ì²´ í‘œ")
    table = out.drop(columns=["ì ìˆ˜"]).copy()
    st.dataframe(
        table,
        column_config={
            "icon": st.column_config.ImageColumn(" ", help="ì±”í”¼ì–¸ ì•„ì´ì½˜", width="small")
        },
        use_container_width=True,
    )
